Exploring AutoGen Libraries \
Compare/Contrast with LangChain
Exploring AutoGen Examples

## LangChain:

1. **LLM-based Applications with Chains, Tools, and Agents:**
   - LangChain is designed for developing applications utilizing Large Language Models (LLMs). It incorporates chains, tools, and agents to facilitate various tasks.

2. **Native Support for Multiple External Data Sources:**
   - LangChain inherently supports integration with multiple external data sources, enhancing its versatility in gathering information.

3. **Chain-Based Approach:**
   - LangChain employs a chain-based approach, organizing tasks into chains that consist of interconnected elements like LLMs, prompts, and output parsers.

4. **LangGraph and Multi-Agent Workflows:**
   - Recently, LangChain introduced LangGraph, supporting Directed Acyclic Graphs (DAGs) in chains. This extension enhances LangChain's capabilities, particularly in multi-agent workflows.

## AutoGen:

1. **Multi-Agent Framework:**
   - AutoGen is a multi-agent framework developed by Microsoft, specifically tailored for building Large Language Model (LLM) applications with workflows involving multi-agent conversations.

2. **Agent-Based Approach:**
   - AutoGen adopts an agent-based approach, where agents play a crucial role in conducting conversations and interacting with each other.

3. **AutoGen Studio:**
   - AutoGen recently introduced AutoGen Studio, a web interface for rapid prototyping. It provides a convenient environment for swiftly creating agents and multi-agent workflows.

![AutoGen Framework](./images/autogen.png)

### **Installation:**
```bash
!pip install pyautogen
```

### **Config List in AutoGen:**

- AutoGen provides several ways to generate a configuration list for agents:

   1. **`get_config_list`:** Generates a configuration list for API calls.
   2. **`config_list_openai_aoai`:** Generates a configuration list for OpenAI and Azure OpenAI endpoints.
   3. **`config_list_from_json`:** Loads configuration from a JSON file, with optional filtering.
   4. **`config_list_from_models`:** Creates configurations based on a provided list of models.
   5. **`config_list_from_dotenv`:** Loads configuration from a .env file, with optional filtering.

```python
import autogen
from autogen import config_list_from_dotenv

config_list = config_list_from_dotenv(
    dotenv_file_path='C:/TrainingMaterial/generative-ai/genai-material/.env',
    filter_dict={
        "model": {
            "gpt-3.5-turbo"
        }
    }
)
```

### **Agents in AutoGen:**

- AutoGen provides an abstraction for creating agents with the following features:

   - **Conversable:** Agents can send or receive messages from other agents.
   - **Customizable:** Agents can be integrated with LLMs, tools, and humans.

### **Multi-Agent Conversational Framework:**


1. **`ConversableAgent`:** A generic class for agents that converse with each other by exchanging messages.
2. **`AssistantAgent`:** Designed to act as an AI Assistant using LLMs.
3. **`UserProxyAgent`:** A proxy for humans.
4. **`GroupChatManager`:** A chat manager that can manage a group chat of multiple agents.

### **Code Generation Agent Example:**

```python
from autogen import AssistantAgent, UserProxyAgent

assistant = AssistantAgent(
    name="assistant",
    llm_config={
        "config_list": config_list,
        "temperature": 0.0,
        "cache_seed": 42
    },
    code_execution_config={
        "use_docker": False
    },
    max_consecutive_auto_reply=10
)

user_proxy = UserProxyAgent(
    name="user_proxy",
    system_message="reply TERMINATE when you are done with the code",
    human_input_mode="TERMINATE",
    code_execution_config={
        "work_dir": "C:/TrainingMaterial/generative-ai/genai-material/trng-1855/trng-git-repo/trng-1855/week-7/",
        "use_docker": False
    },
    llm_config={
        "config_list": config_list,
        "temperature": 0.0,
        "cache_seed": 42
    },
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    max_consecutive_auto_reply=10
)

product_manager = AssistantAgent(
    name="product_manager",
    llm_config={
        "config_list": config_list,
        "temperature": 0.0,
        "cache_seed": 42
    },
    code_execution_config={
        "use_docker": False
    },
    max_consecutive_auto_reply=10,
    system_message="Agent to ask unique coding questions as a continuation for user questions"
)
```

### **Agent Group Chat Example:**

```python
from autogen import GroupChat, GroupChatManager

agent_group = GroupChat(agents=[assistant, user_proxy, product_manager], messages=[], max_round=10)

manager = GroupChatManager(
    groupchat=agent_group,
    max_consecutive_auto_reply=10,
    llm_config={
        "config_list": config_list,
        "temperature": 0.0,
        "cache_seed": 42
    },
    code_execution_config={
        "use_docker": False
    }
)

result = user_proxy.initiate_chat(
    manager,
    message="Code to search a number in a list?",
)
```

### **References:**

- [AutoGen Docs](https://microsoft.github.io/autogen/docs/Getting-Started)
- [AutoGen SDK](https://microsoft.github.io/autogen/docs/reference/agentchat/conversable_agent)

